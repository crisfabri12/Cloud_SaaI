# Aplicaci贸n SaaI distribuida en Kubernetes con Pulumi y Kind

Este proyecto representa una aplicaci贸n web SaaI (Software as an Island) distribuida y desplegada localmente en un cl煤ster de Kubernetes usando [Kind](https://kind.sigs.k8s.io/) y gestionada con [Pulumi](https://www.pulumi.com/).

---

##  驴Qu茅 es SaaI y qu茅 rol cumple Pulumi?

**SaaI (Software as an Island)** es un enfoque arquitect贸nico donde cada componente del sistema funciona como una "isla": independiente, aut贸noma y capaz de escalar o fallar sin afectar al resto del sistema. Esto ofrece:

* **Desacoplamiento fuerte**: cada servicio puede evolucionar y escalar por separado.
* **Resiliencia**: una isla puede fallar sin comprometer las otras.
* **Escalabilidad inteligente**: se asignan recursos solo donde hay demanda.

En este proyecto, SaaI se representa mediante:

* Despliegues independientes para frontend, backend y base de datos.
* Recursos separados y aislados por tipo de componente.
* Autoscalado en el backend seg煤n la carga.
* Distribuci贸n de pods en m煤ltiples nodos para redundancia.

### О 驴Y qu茅 es Pulumi?

**Pulumi** es una herramienta de infraestructura como c贸digo (IaC) que permite definir y desplegar recursos de infraestructura utilizando lenguajes de programaci贸n modernos. En este caso, usamos **TypeScript** para definir el cl煤ster, los servicios, las im谩genes, los deployments y dem谩s recursos de Kubernetes.

Esto nos permite:

* Automatizar completamente la creaci贸n del cl煤ster con Kind.
* Declarar todos los recursos de Kubernetes como c贸digo versionable.
* Reutilizar estructuras y aplicar l贸gica en la configuraci贸n.
* Mantener un entorno reproducible y portable.

Pulumi act煤a como el "capit谩n del archipi茅lago": asegura que cada isla (servicio) est茅 en su sitio, configurada y conectada como debe ser.

---

##  Tecnolog铆as principales

* **Kubernetes**: Orquestaci贸n de contenedores.
* **Kind**: Cl煤ster Kubernetes local con nodos distribuidos.
* **Pulumi**: Infraestructura como c贸digo con TypeScript.
* **Docker**: Contenerizaci贸n de la aplicaci贸n.
* **Horizontal Pod Autoscaler (HPA)**: Autoescalado de pods basado en uso de CPU.
* **PostgreSQL**: Base de datos persistente desplegada con StatefulSet.
* **Nginx Ingress Controller**: Exposici贸n HTTP de los servicios.

---

##  Arquitectura distribuida

El cl煤ster contiene 1 nodo de control y 2 nodos trabajadores:

* **Control Plane**: `pulumi-cluster-control-plane`
* **Worker Nodes**: `pulumi-cluster-worker`, `pulumi-cluster-worker2`

La distribuci贸n de pods se puede observar en los logs:

```bash
backend-dep-6b6bf84599-gknnt     -> pulumi-cluster-worker
backend-dep-6b6bf84599-zlvrl     -> pulumi-cluster-worker2
frontend-dep-dac293ed-7f6f8474-8hkgz -> pulumi-cluster-worker
frontend-dep-dac293ed-7f6f8474-ggsd7 -> pulumi-cluster-worker2
postgres-sts-1071c13e-0              -> pulumi-cluster-worker
```

Esto demuestra una distribuci贸n efectiva de carga entre los nodos, respaldando el enfoque SaaI, donde cada "isla" de funcionalidad (frontend, backend, base de datos) puede escalar y aislarse de forma independiente.

---

##  Componentes desplegados

###  Backend

* Imagen: `crisfabri98/backend:latest`
* Deployment: `backend-dep`
* HPA: `backend-hpa` (CPU target 30%, min 1 pod, max 5 pods)
* Service: `backend-svc`

###  Frontend

* Imagen: `crisfabri98/frontend:latest`
* Deployment: `frontend-dep-<hash>`
* Service: `frontend-svc`

###  Base de datos

* Imagen: `postgres`
* StatefulSet: `postgres-sts-<hash>`
* Servicios: `postgres` y `postgres-headless`

###  Ingress

* Controlador: `ingress-nginx-controller`
* Permite acceso HTTP a `frontend` y `backend` desde el exterior.

---

##  Autoscaling

El autoscaler horizontal est谩 habilitado para el backend:

```bash
NAME          REFERENCE                TARGETS       MINPODS   MAXPODS   REPLICAS
backend-hpa   Deployment/backend-dep   cpu: 1%/30%   1         5         2
```

Esto permite escalar autom谩ticamente los pods del backend al aumentar la carga. Actualmente est谩 funcionando con 2 r茅plicas.

---

## 锔 Comandos 煤tiles

```bash
# Ver despliegues por namespace
kubectl get deployments -A

# Ver recursos en el namespace principal
kubectl get all -n my-app

# Ver distribuci贸n de pods en nodos
kubectl get pods -A -o wide

# Ver el estado del autoscaler
kubectl get hpa -n my-app
```

---

##  Observaciones clave

* La distribuci贸n de pods es balanceada entre nodos workers.
* El HPA ya est谩 activamente manteniendo 2 r茅plicas.
* No se est谩 usando Prometheus ni Grafana en esta configuraci贸n.
* La base de datos est谩 corriendo como StatefulSet para mantener persistencia.

---

### Л 驴Por qu茅 elegir este enfoque?

* Ideal para entornos de desarrollo, pruebas y ense帽anza de Kubernetes.
* Permite experimentar con pr谩cticas reales de DevOps y arquitecturas distribuidas sin necesidad de un proveedor cloud.
* Facilita el dise帽o de sistemas escalables, mantenibles y resilientes.
* Reduce fricci贸n entre desarrollo y operaciones.

Este proyecto demuestra que un enfoque SaaI no es exclusivo del mundo cloud: puede implementarse localmente de forma profesional, usando herramientas modernas y abiertas.

> 驴Por qu茅 levantar monolitos cuando puedes crear islas aut贸nomas y hermosas?

---

##  Futuras mejoras sugeridas

* Integrar **Prometheus y Grafana** para monitoreo y visualizaci贸n.
* Habilitar vol煤menes persistentes reales (actualmente usando Local Path Provisioner).
* Implementar una estrategia de logging centralizado (por ejemplo, Loki).
* Automatizar pruebas de carga para validar el escalado.

---
